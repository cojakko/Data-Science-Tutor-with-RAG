
CHAPTER 9. CONVOLUTIONAL NETWORKSFigure 9.19: Many machine learning algorithms learn features that detect edges or speciﬁccolors of edges when applied to natural images. These feature detectors are reminiscentof the Gabor functions known to be present in the primary visual cortex. (Left)Weightslearned by an unsupervised learning algorithm (spike and slab sparse coding) appliedto small image patches. (Right)Convolution kernels learned by the ﬁrst layer of a fullysupervised convolutional maxout network. Neighboring pairs of ﬁlters drive the samemaxout unit.9.11 Convolutional Networks and the History of DeepLearningConvolutional networks have played an important role in the history of deeplearning. They are a key example of a successful application of insights obtainedby studying the brain to machine learning applications. They were also some ofthe ﬁrst deep models to perform well, long before arbitrary deep models wereconsidered viable. Convolutional networks were also some of the ﬁrst neuralnetworks to solve important commercial applications and remain at the forefrontof commercial applications of deep learning today. For example, in the 1990s, theneural network research group at AT&T developed a convolutional network forreading checks (LeCun et al., 1998b). By the end of the 1990s, this system deployedby NCR was reading over 10 percent of all the checks in the United States. Later,several OCR and handwriting recognition systems based on convolutional netswere deployed by Microsoft (Simard et al., 2003). See chapter 12 for more detailson such applications and more modern applications of convolutional networks. SeeLeCun et al. (2010) for a more in-depth history of convolutional networks up to2010.Convolutional networks were also used to win many contests. The currentintensity of commercial interest in deep learning began when Krizhevsky et al.365
CHAPTER 9. CONVOLUTIONAL NETWORKS(2012) won the ImageNet object recognition challenge, but convolutional networkshad been used to win other machine learning and computer vision contests withless impact for years earlier.Convolutional nets were some of the ﬁrst working deep networks trained withback-propagation. It is not entirely clear why convolutional networks succeededwhen general back-propagation networks were considered to have failed. It maysimply be that convolutional networks were more computationally eﬃcient thanfully connected networks, so it was easier to run multiple experiments with themand tune their implementation and hyperparameters. Larger networks also seemto be easier to train. With modern hardware, large fully connected networksappear to perform reasonably on many tasks, even when using datasets that wereavailable and activation functions that were popular during the times when fullyconnected networks were believed not to work well. It may be that the primarybarriers to the success of neural networks were psychological (practitioners didnot expect neural networks to work, so they did not make a serious eﬀort to useneural networks). Whatever the case, it is fortunate that convolutional networksperformed well decades ago. In many ways, they carried the torch for the rest ofdeep learning and paved the way to the acceptance of neural networks in general.Convolutional networks provide a way to specialize neural networks to workwith data that has a clear grid-structured topology and to scale such models tovery large size. This approach has been the most successful on a two-dimensionalimage topology. To process one-dimensional sequential data, we turn next toanother powerful specialization of the neural networks framework: recurrent neuralnetworks.366